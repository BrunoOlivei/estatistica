
# Introdução

Frequentemente estaremos interessados em analisar o comportamento conjunto de duas ou mais variáveis aleatórias.

O principal objetivo das análises nessa situação é explorar relações (similaridades) entre as colunas, ou algumas vezes entre as linhas, sendo a distribuição conjunta de frequências um instrumento poderoso para a compreensão do comportamento dos dados. 

Um exemplo seria comparar os salários dos casados e solteiros, uma reordenação dos dados poderia colocar os casados na primeira posição e os solteiros nas últimas, e nosso objetivo passaria a ser comparar, na coluna de salários, o comportamento de S na parte superior com a inferior. A apresentação de um ou outro modo será ditada principalmente pelo interesse e técnicas de análise à disposição do pesquisador.

Quando consideramos duas variáveis (ou dois conjuntos de dados), podemos ter três situações:

1. as duas variáveis são qualitativas;
2. as duas variáveis são quantitativas; e
3. uma variável é qualitativa e a outra é quantitativa.

As técnicas de análise de dados nas três situações são diferentes. Quando as variáveis são **qualitativas** os dados são resumidos em _tabelas de dupla entrada (ou de contingência)_, em que aparecerão as **frequências absolutas ou contagens de indivíduos** que pertencem simultaneamente a categorias de uma e outra variável. Quando as duas variáveis são **quantitativas**, as **observações são provenientes de mensurações**, e técnicas como **gráficos de dispersão** ou de **quantis** são apropriadas. Quando temos uma variável **qualitativa e outra quantitativa**, em geral, analisamos **o que acontece com a variável quantitativa quando os dados são categorizados de acordo com os diversos atributos da variável qualitativa**. Mas podemos ter também o caso de duas variáveis quantitativas agrupadas em classes. Por exemplo, podemos querer analisar a associação entre renda e consumo de certo número de famílias e, para isso agrupamos as famílias em classes de renda e classes de consumo. Desse modo, recaímos novamente numa tabela de dupla entrada.

Para efeitos práticos, iremos entender a existência de associação como a _mudança_ de opinião sobre o comportamento de uma variável na presença ou não de informações sobre a segunda variável. 

Exemplo: existe relação entre a altura de pessoas e o sexo em dada comunidade? Pode se fazer uma primeira pergunta: qual a frequência esperada de uma pessoa dessa população ter mais de 170cm de altura? E também uma segunda: qual a frequência esperada de uma mulher ter mais de 170cm de altura? Se a resposta para as duas perguntas for a mesma, diríamos que _não há_ associação entre as variáveis altura e sexo. Porém se as respostas forem diferentes, isso significa uma provável associação, e devemos incorporar esse conhecimento para melhorar o entendimento sobre os comportamentos da variáveis. 

# Variáveis Qualitativas

Suponha que queiramos analisar o comportamento conjunto das variáveis grau de instrução e região de procedência.

```python
df_pivot = pd.pivot_table(df[['Região de Procedência', 'Grau de Instrução']], 
                index="Região de Procedência",
                columns="Grau de Instrução", 
                aggfunc=len)
df_pivot.loc["Total"] = df_pivot.sum() # Total das colunas
df_pivot["Total"] = df_pivot.sum(axis=1) # Total das linhas
```

Grau de Instrução / Região de Procedência | ensino fundamental |ensino médio | superior | Total 
------------------------------------------|--------------------|-------------|----------|-------
capital | 4| 5| 2| 11 
interior | 3| 7| 2| 12
outra | 5 | 6 | 2 | 13
Total | 12 | 18| 6 | 36

A linha de totais fornece a distribuição da variável Grau de Instrução, enquanto a coluna dos totais fornece a distribuição da variável Região de Procedência, sendo chamadas de _distribuições marginais_ enquanto a tabela constitui a _distribuição conjunta de Grua de Instrução e Região de Procedência_. 

Aqui existem três possibilidades de expressar a proporção de cada casela:

1. em relação ao total geral;
2. em relação ao total de cada linha;
3. ou em relação ao total de cada coluna.

De acordo com o objetivo do problema em estudo, uma delas será a mais conveniente.

A tabela a seguir apresenta a distribuição conjunta das frequências relativas, expressas como proporções do total geral. 

```python
df_pivot = pd.pivot_table(
    df[['Região de Procedência', 'Grau de Instrução']], 
    index="Região de Procedência",
    columns="Grau de Instrução", 
    aggfunc=lambda x: int(round(len(x) / len(df) * 100, 0)),
    margins=True,
    margins_name="Total",
)
df_pivot
```

Grau de Instrução / Região de Procedência | ensino fundamental |ensino médio | superior | Total 
------------------------------------------|--------------------|-------------|----------|-------
capital | 11 | 14 | 6 | 31 
interior | 8 | 19 | 6 | 33
outra | 14 | 17 | 6 | 36
Total | 33 | 50 | 17 | 100

A tabela seguinte apresenta a distribuição das proporções em relação ao total das colunas.

```python
joint_df = (pd.crosstab(index=df["Região de Procedência"],
                       columns=df["Grau de Instrução"],
                       normalize="columns") * 100).round(0).astype(int)
joint_df.loc["Total"] = joint_df.sum()
joint_df
```

Grau de Instrução / Região de Procedência | ensino fundamental |ensino médio | superior  
------------------------------------------|--------------------|-------------|----------
capital | 33 | 28 | 33  
interior | 25 | 39 | 33 
outra | 42 | 33 | 33 
Total | 100 | 100 | 100

```python
sns.set()
joint_df.iloc[:3].T.plot(kind='bar', stacked=True)
```

![[Distribuição da região de procedência por grau de instrução.png]]

# Associação entre Variáveis Qualitativas

Um dos principais objetivos de se construir uma distribuição conjunta de duas variáveis qualitativas é descrever a associação entre elas, isto é, queremos conhecer o grau de _dependência_ entre elas, de modo que possamos prever melhor o resultado de uma delas quando conhecermos a realização da outra.

Exemplo, suponhamos que uma pessoa seja sorteada ao acaso na população da cidade de São Paulo e devamos adivinhar o sexo dessa pessoa. Como a proporção de pessoas de cada sexo é aproximadamente a mesma, o resultado desse exercício de adivinhação poderia ser qualquer um dos sexos. Mas se a mesma pergunta fosse feita e também fosse dito que a pessoa sorteada trabalha na indústria siderúrgica, então nossa resposta mais provável seria que a pessoa é do sexo masculino. Ou seja, há um grau de dependência grande entre as variáveis sexo e ramo de atividade.

Queremos verificar se existe ou não associação entre o sexo e a carreira escolhida por 200 alunos.

Curso Escolhido / Sexo | Masculino | Feminino | Total
-----------------------|-----------|----------|------
Economia | 85 | 35 | 120
Administração | 55 | 25 | 80
Total | 140 | 60 | 200

Fica muito difícil tirar alguma conclusão devido a diferença entre os **totais marginais**. Devemos considerar as proporções por linhas ou colunas. 

Curso Escolhido / Sexo | Masculino | Feminino | Total
-----------------------|-----------|----------|------
Economia | 61% | 58% | 60%
Administração | 39% | 42% | 40%
Total | 100% | 100% | 100%

Independentemente do sexo, 60% das pessoas preferem Economia e 40% Administração. Não havendo dependência entre as variáveis, esperaríamos essas mesmas proporções para cada sexo. Observando a tabela vemos que as proporções do sexo masculino e do sexo feminino são próximas das marginais. Esse conjunto parece indicar não haver dependência entre as duas variáveis. Concluindo as variáveis sexo e escolha do curso parecem ser _não associadas_.

# Medidas de Associação entre Variáveis Qualitativas

Quantificação do grau de associação entre duas variáveis é feito pelos chamados _coeficientes de associação ou correlação_. São medidas que descrevem por meio de um único número, a associação (ou dependência) entre duas variáveis. Esses coeficientes usualmente variam entre 0 e 1, ou entre -1 e +1, e a proximidade de zero indica falta de associação.

Algumas medidas utilizadas são o _coeficiente de contingência_ (K. Pearson) e uma modificação dele.

Estado | Consumidor | Produtor | Escola | Outro | Total
-------|------------|----------|--------|-------|-------
São Paulo | 214 | 237 | 78 | 119 | 648
Paraná | 51  | 102 | 126 | 22 | 301
Rio G. do Sul | 111 | 304 | 139 | 48 | 602
Total | 376 | 643 | 343 | 189 | 1551

```python
states = ["São Paulo", "Paraná", "Rio Grande do Sul"]
customers = [214, 51, 111]
products = [237, 102, 304]
school = [78, 126, 139]
others = [119, 22, 48]

df = pd.DataFrame(
    {
        "Estados": states,
        "Consumidor": customers,
        "Produtor": products,
        "Escola": school,
        "Outros": others
    }
)
df = df.set_index("Estados")
df_with_total = df.copy()
df_with_total.loc["Total"] = df_with_total.sum()
df_with_total["Total"] = df_with_total.sum(axis=1)
```

Tomando por base os valores relativos do total de tipos de cooperativas, podemos observar uma certa dependência entre as variáveis. Caso não houvesse associação, esperaríamos que em cada estado tivéssemos 25% de cooperativas de consumidores, 42% de produtores, 22% de escolas e 12% de outros tipos:

Estado | Consumidor | Produtor | Escola | Outro | Total
-------|------------|----------|--------|-------|-------
São Paulo | 157 (24%) | 269 (42%) | 143 (22%) | 79 (12%) | 648 (100%)
Paraná | 73 (24%) | 124 (42%) | 67 (22%) | 37 (12%) | 301 (100%)
Rio G. do Sul | 146 (24%) | 250 (42%) | 133 (22%) | 73 (12%) | 602 (100%)
Total | 376 (24%) | 643 (42%) | 343 (22%) | 189 (12%) | 1551 (100%)

```python
df_percents = (df_with_total.div(df_with_total["Total"], axis=0) * 100)
df_percents = df_percents.round(2)
df_percents
```

Comparando as duas tabelas podemos verificar as discrepâncias existentes entre os valores observados e os esperados, caso as variáveis não fossem associadas.

Estado | Consumidor | Produtor | Escola | Outro 
-------|------------|----------|--------|-------
São Paulo | 57 (20,69) | -32 (3,81) | -65 (29,55) | 40 (20,25) 
Paraná | -22 (6,63) | -22 (3,90) | 59 (51,96) | -15 (6,08) 
Rio G. do Sul | -35 (8,39) | 54 (11,66) | 6 (0,27%) | -25 (8,56)

```python
df_espected = pd.DataFrame(
    {
        "Estados": states,
        "Consumidor": list(((df_percents.loc["Total", "Consumidor"] / 100) * df_with_total.loc[:, "Total"]).values)[:len(states)],
        "Produtor": list(((df_percents.loc["Total", "Produtor"] / 100) * df_with_total.loc[:, "Total"]).values)[:len(states)],
        "Escola": list(((df_percents.loc["Total", "Escola"] / 100) * df_with_total.loc[:, "Total"]).values)[:len(states)],
        "Outros": list(((df_percents.loc["Total", "Outros"] / 100) * df_with_total.loc[:, "Total"]).values)[:len(states)],
    }
)
df_espected = df_espected.set_index("Estados")
df_espected = df_espected.round(0).astype(int)
df_espected
```

```python
df_desv = (df - df_espected).round(0).astype(int)
df_desv
```

Desvios relativos de cada casela (estado / tipo) é dado por:
$$ \frac{(o_i - e_i)^2}{e_i} $$

Escola - São Paulo = (143 - 57)² / 143 = 29,55

```python
sao_paulo_escole_qui_quadrado = ((df.loc["São Paulo", "Escola"] - df_espected.loc["São Paulo", "Escola"]) ** 2) / df_espected.loc["São Paulo", "Escola"]
sao_paulo_escole_qui_quadrado
```

A medida de afastamento global pode ser dada pela soma de todas as medidas de desvios relativos, sendo denominada (qui-quadrado) de Pearson.

$$ \chi^2 = \sum_{i=1}^r \sum_{j=1}^s \frac{(n_{ij}-n_{ij}^*)^2}{n_{ij}^*} $$

Um valor grande indica associação entre as variáveis.

```python
r = df.shape[0] # Variáveis independentes = 3
c = df.shape[1] # Variáveis dependentes = 4
n = df_with_total.loc["Total", "Total"] # número de observações = 1551
qui_quadrado = ((df - df_espected) ** 2 / df_espected).sum().sum()
qui_quadrado # 172.0847
```

Para fazer comparações seria interessante ter uma medida que varie num intervalo limitado entre (0,1), por exemplo, zero indicando independência e um dependência completa.

Pearson definiu uma medida de associação baseada no qui-quadrado, chamada _Coeficiente de Contingência_: 

$$ C = \sqrt{\frac{\chi^2}{\chi^2 + n}} $$

Contudo esse coeficiente pode não atingir o valor máximo igual um, no caso de r = s

> [!Note]
> **r** são as variáveis independentes, no exemplo os estados.
> **s** são as variáveis dependentes, no exemplo os tipos.

```python
C = sqrt(qui_quadrado / (qui_quadrado + n))
C # 0.3160224058082541
```

Um coeficiente, sugerido por Tschuprov, pode atingir o máximo igual a 1, se r = s:

$$ T = \sqrt{\frac{\chi^2}{n\sqrt{(r-1)(s-1)}}} $$

```python
T = sqrt(qui_quadrado / (n * sqrt((r - 1) * (c - 1))))
T # 0.21282737230781038
```

Outra medida de associação foi proposta por Cramér:

$$ V = \sqrt{\frac{\chi^2}{n \times \min{((r-1), (c-1))}}} $$

```python
V = sqrt(qui_quadrado / (n * (min(r-1, c-1))))
V # 0.23553220495038263
```

# Associação entre Variáveis Quantitativas

Um dispositivo bastante útil para se verificar a associação entre duas variáveis quantitativas, ou entre dois conjuntos de dados, é o gráfico de dispersão.

```python
agentes = ["A", "B", "C", "D", "E", "F", "G", "H", "I", "J"]
ano_servico = [2, 3, 4, 5, 4, 6, 7, 8, 8, 10]
num_clientes = [48, 50, 56, 52, 43, 60, 62, 58, 64, 72]

df = pd.DataFrame(
    {
        "Agentes": agentes,
        "Anos de Serviço": ano_servico,
        "Número de Clientes": num_clientes
    }
)
df = df.set_index("Agentes")
df
```

| Agentes | Anos de Serviço | Número de Clientes |
| ------- | --------------- | ------------------ |
| A       | 2               | 48                 |
| B       | 3               | 50                 |
| C       | 4               | 56                 |
| D       | 5               | 52                 |
| E       | 4               | 43                 |
| F       | 6               | 60                 |
| G       | 7               | 62                 |
| H       | 8               | 58                 |
| I       | 8               | 64                 |
| J       | 10              | 72                 |

```python
plt.scatter(df["Anos de Serviço"], df["Número de Clientes"])
plt.title("Anos de Serviço x Número de Clientes")
plt.xlabel("Anos de Serviço")
plt.ylabel("Número de Clientes")
plt.show()
```

![[Gráfico de dispersão anos de serviço e número de clientes.png]]

Podemos observar que parece haver uma associação entre as variáveis, porque no conjunto, a medida que aumenta o tempo de serviço, aumenta o número de clientes.

Numa pesquisa feita com dez famílias com renda bruta mensal entre 10 e 60 salários mínimos, mediram-se a porcentagem da renda bruta anual gasta com assistência médica.

```python
familia = ["A", "B", "C", "D", "E", "F", "G", "H", "I", "J"]
renda = [12, 16, 18, 20, 28, 30, 40, 48, 50, 54]
gasto_medico = [7.2, 7.4, 7.0, 6.5, 6.6, 6.7, 6.0, 5.6, 6.0, 5.5]

df = pd.DataFrame(
    {
        "Família": familia,
        "Renda Bruta Mensal (Sal Min)": renda,
        "Gasto Médico Anual (% Anual)": gasto_medico
    }
)
df = df.set_index("Família")
df
```

| Família | Renda Bruta Mensal (Sal Min) | Gasto Médico Anual (% Anual) |
| ------- | ---------------------------- | ---------------------------- |
| A       | 12                           | 7.2                          |
| B       | 16                           | 7.4                          |
| C       | 18                           | 7.0                          |
| D       | 20                           | 6.5                          |
| E       | 28                           | 6.6                          |
| F       | 30                           | 6.7                          |
| G       | 40                           | 6.0                          |
| H       | 48                           | 5.6                          |
| I       | 50                           | 6.0                          |
| J       | 54                           | 5.5                          |

Observando o gráfico de dispersão, vemos que existe uma associação "inversa", isto é, aumentando a renda bruta diminui a porcentagem sobre ela gasta em assistência médica.

```python
plt.scatter(df["Renda Bruta Mensal (Sal Min)"], df["Gasto Médico Anual (% Anual)"])
plt.title("Renda Bruta Mensal (Sal Min) x Gasto Médico Anual (% Anual)")
plt.xlabel("Renda Bruta Mensal (Sal Min)")
plt.ylabel("Gasto Médico Anual (% Anual)")
plt.show()
```

![[Gráfico de dispersão renda bruta mensal e porcentagem da renda gasta em saúde.png]]

Oito indivíduos foram submetidos a um teste sobre conhecimento de língua estrangeira e, em seguida, mediu-se o tempo gasto para cada um aprender a operar uma determinada máquina.

```python
individuos = ["A", "B", "C", "D", "E", "F", "G", "H"]
pontos_teste = [45, 52, 61, 70, 74, 76, 80, 90]
tempo_minutos = [343, 368, 355, 334, 337, 381, 345, 375]

df = pd.DataFrame(
    {
        "Indivíduos": individuos,
        "Pontos no Teste": pontos_teste,
        "Tempo (minutos)": tempo_minutos
    }
)
df = df.set_index("Indivíduos")
df
```

| Indivíduos | Pontos no Teste | Tempo (minutos) |
| ---------- | --------------- | --------------- |
| A          | 45              | 343             |
| B          | 52              | 368             |
| C          | 61              | 355             |
| D          | 70              | 334             |
| E          | 74              | 337             |
| F          | 76              | 381             |
| G          | 80              | 345             |
| H          | 90              | 375             |

Do gráfico de dispersão concluímos que parece não haver associação entre as duas variáveis, pois conhecer o resultado do teste não ajuda a prever o tempo gasto para aprender a operar a máquina.

```python
plt.scatter(df["Pontos no Teste"], df["Tempo (minutos)"])
plt.title("Pontos no Teste x Tempo (minutos)")
plt.xlabel("Pontos no Teste")
plt.ylabel("Tempo (minutos)")
plt.show()
```

![[Gráfico de dispersão para resultado no teste e tempo de operação.png]]

## Coeficiente de relação linear

É uma medida do grau de associação entre duas variáveis e também da proximidade dos dados uma reta.

Média x = 5.7
Média y = 56.5
Desvio Padrão x = 2.41
Desvio Padrão y = 8.11

```python
def desvio_padrao(data):
    x_mean = data.mean()
    s = []
    for x in data:
        s.append((x - x_mean) ** 2)
    return sqrt(sum(s) / len(data))
```

```python
x_mean = df["Anos de Serviço"].mean()
y_mean = df["Número de Clientes"].mean()
x_std = desvio_padrao(df["Anos de Serviço"])
y_std = desvio_padrao(df["Número de Clientes"])
```

```python
df["x-x_mean"] = df["Anos de Serviço"] - x_mean
df["y-y_mean"] = df["Número de Clientes"] - y_mean
df["y-y_mean/dp(y)"] = df["y-y_mean"] / y_std
df["x-x_mean/dp(x)"] = df["x-x_mean"] / x_std
df["(x-x_mean/dp(x)) * (y-y_mean/dp(y))"] = df["x-x_mean/dp(x)"] * df["y-y_mean/dp(y)"]
df
```

| Agentes | Anos de Serviço $x$ | Número de Clientes $y$ | $x_{i}-\overline{x}$ | $y_{i}-\overline{y}$ | $\frac{y_{i}-\overline{y}}{dp(Y)}$ | $\frac{x_{i}-\overline{x}}{dp(X)}$ | $\frac{x_{i}-\overline{x}}{dp(X)} \times \frac{y_{i}-\overline{y}}{dp(Y)}$|
| ------- | --------------- | ------------------ | -------- | -------- | -------------- | -------------- | ----------------------------------- |
| A       | 2               | 48                 | -3.7     | -8.5     | -1.047469      | -1.535019      | 1.607884                            |
| B       | 3               | 50                 | -2.7     | -6.5     | -0.801005      | -1.120149      | 0.897245                            |
| C       | 4               | 56                 | -1.7     | -0.5     | -0.061616      | -0.705279      | 0.043456                            |
| D       | 5               | 52                 | -0.7     | -4.5     | -0.554542      | -0.290409      | 0.161044                            |
| E       | 4               | 43                 | -1.7     | -13.5    | -1.663627      | -0.705279      | 1.173321                            |
| F       | 6               | 60                 | 0.3      | 3.5      | 0.431311       | 0.124461       | 0.053681                            |
| G       | 7               | 62                 | 1.3      | 5.5      | 0.677774       | 0.539331       | 0.365544                            |
| H       | 8               | 58                 | 2.3      | 1.5      | 0.184847       | 0.954201       | 0.176382                            |
| I       | 8               | 64                 | 2.3      | 7.5      | 0.924237       | 0.954201       | 0.881908                            |
| J       | 10              | 72                 | 4.3      | 15.5     | 1.910090       | 1.783941       | 3.407487                            |
| **Total**   | **57**              | **565**                | **0**        | **0**        |                |                | **8.767952**                            |

Com a soma dos produtos das coordenadas reduzidas (última coluna) calculado, dividimos pelo úmero de observações: 

$$ (X,Y) = 8.767952 / 10 = 0.876795 $$

```python
(df["(x-x_mean/dp(x)) * (y-y_mean/dp(y))"].sum() / (df.shape[0])) * 100
```

Para este exemplo o **grau de associação linear** é **87.68%**

Utilizando a biblioteca **pandas**

```python
df.corr()
```

|     | Anos de Serviço | Número de Clientes         |
| ------------------ | ------------------ | -------- |
| Anos de Serviço    | 1.000000           | 0.876795 |
| Número de Clientes | 0.876795           | 1.000000 |

$$ corr(X,Y) = \frac{1}{n} \sum{\left( \frac{x_i - \overline{x}}{dp(X)}\right)\left( \frac{y_i - \overline{y}}{dp(Y)}\right)} $$

Ou ainda:

Covariância que é dada por:

$$cov(X,Y) = \frac{\sum_{i=1}^{n}(x_i-\overline{x})(y_i-\overline{y})}{n}$$

Resultando em:

$$ corr(X,Y) = \frac{cov(X,Y)}{dp(X)dp(Y)} $$
```python
((df["x-x_mean"] * df["y-y_mean"]).sum() / 10) / (x_std * y_std) # 0.876795
```

